#!/usr/bin/env python3
"""
Fix Staffing Data in Azure Search Index
=======================================

This script removes the incorrectly added staffing-only documents
and properly merges the detailed staffing data into existing SOW documents.
"""

import os
import requests
from dotenv import load_dotenv

class StaffingDataFixer:
    """Fix the staffing data in the Azure Search index"""
    
    def __init__(self):
        self.search_endpoint = None
        self.search_key = None
        self.index_name = "octagon-sows-parsed"
        
        # Detailed staffing data from ChatGPT extraction
        self.detailed_staffing_data = {
            "company_4_sow_1": [
                "VP, Client Services â€“ 525 hrs (25% + Onboarding)",
                "Director, Client Services â€“ 450 hrs (25%)",
                "VP, Experiences â€“ 420 hrs (20% + Onboarding)",
                "Sr. Director, Experiences â€“ 1,350 hrs (75% + Onboarding)",
                "Experiential Manager â€“ 1,800 hrs (100%)",
                "Experiential Manager â€“ 1,800 hrs (100%)",
                "Sr. Event Executive â€“ 1,800 hrs (100%)",
                "Sr. Event Executive â€“ 1,650 hrs (100% Ã— 11 months)",
                "Event Executive â€“ 1,650 hrs (100% Ã— 11 months)",
                "Director, Experiences Production â€“ 900 hrs (50%)",
                "Sr. Event Executive, Experiences Production â€“ 900 hrs (50%)"
            ],
            "company_2_sow_1": [
                "EVP (US) â€“ 5% â€“ 60 hrs",
                "SVP (US) â€“ 50% â€“ 920 hrs",
                "VP (US) â€“ 20% â€“ 180 hrs",
                "VP (US) â€“ 100% â€“ 1,800 hrs",
                "SME (US) â€“ 100% â€“ 1,800 hrs",
                "AD (US) â€“ 100% â€“ 1,800 hrs",
                "AM (US) â€“ 100% â€“ 1,800 hrs",
                "SAM (US) â€“ 30% â€“ 540 hrs",
                "AE (UK) â€“ 13% â€“ 220 hrs"
            ],
            "company_2_sow_3": [
                "Derek Aframe (EVP, US) â€“ 5% â€“ 83 hrs",
                "Hannah Woodfin (SVP, US) â€“ 10% â€“ 190 hrs",
                "Sarah Binkenstein Hubner (AD, US) â€“ 100% â€“ 1,800 hrs",
                "Max Boeinelmann (Toolkit Lead, AD, US) â€“ 100% â€“ 1,800 hrs",
                "Caitlin Blankenship (AD, US) â€“ 100% â€“ 1,800 hrs",
                "AM Finance â€“ 100% â€“ 1,800 hrs",
                "Svetlana Hanau (VP) â€“ 25% â€“ 450 hrs",
                "Ted Murphy (VP) â€“ 25% â€“ 450 hrs",
                "Marina T (AM, Hospitality) â€“ 100% â€“ 1,800 hrs",
                "SAM BG Project (Febâ€“Jul, FRA) â€“ 75% â€“ 690 hrs"
            ],
            "company_1_sow_3": [
                "David Hargis (SVP, US) â€“ 2.5% â€“ 45 hrs",
                "Cynthia Sotero (VP, US) â€“ 2.5% â€“ 45 hrs",
                "Chelsea Pham (Account Manager, US) â€“ 2.0% â€“ 36 hrs"
            ],
            "company_1_sow_4": [
                "Rob McGuire (SVP) â€“ 540 hrs",
                "Thomas Carter (Director) â€“ 540 hrs",
                "Nicole Carter (Sr. Manager) â€“ 540 hrs",
                "Carol Patrick (Director) â€“ 540 hrs",
                "Leslie Knott (Experiential Director) â€“ 540 hrs",
                "Thomas Carter (Experiential Manager) â€“ 540 hrs"
            ],
            "company_1_sow_1": [
                "Account Director â€“ 780 hrs (Formula 1 â€“ Las Vegas, Day-to-Day Lead)",
                "Account Manager â€“ 900 hrs (API Day-to-Day Manager)",
                "Sr. Account Executive (SAE) â€“ 900 hrs (GRAMMY's Day-to-Day Manager)",
                "Account Executive (AE) â€“ 800 hrs (Program Support)"
            ]
        }
    
    def load_environment(self):
        """Load environment variables"""
        env_path = Path(__file__).parent / '.env'
        if env_path.exists():
            load_dotenv(env_path)
            print(f"âœ… Loaded environment from {env_path}")
        else:
            print("âš ï¸ .env file not found, using system environment variables")
        
        self.search_endpoint = os.getenv('SEARCH_ENDPOINT')
        self.search_key = os.getenv('SEARCH_KEY')
        
        if not self.search_endpoint or not self.search_key:
            raise ValueError("Missing SEARCH_ENDPOINT or SEARCH_KEY in environment variables")
        
        self.search_endpoint = self.search_endpoint.rstrip('/')
    
    def get_all_documents(self):
        """Get all documents from the index"""
        
        url = f"{self.search_endpoint}/indexes/{self.index_name}/docs/search?api-version=2023-11-01"
        headers = {'Content-Type': 'application/json', 'api-key': self.search_key}
        
        payload = {
            "search": "*",
            "top": 100,
            "select": "id,file_name,client_name,project_title,staffing_plan"
        }
        
        try:
            response = requests.post(url, headers=headers, json=payload)
            
            if response.status_code == 200:
                results = response.json()
                return results.get('value', [])
            else:
                print(f"âŒ Error getting documents: {response.status_code} - {response.text}")
                return []
                
        except Exception as e:
            print(f"âŒ Error getting documents: {e}")
            return []
    
    def delete_document(self, document_id):
        """Delete a document from the index"""
        
        url = f"{self.search_endpoint}/indexes/{self.index_name}/docs/index?api-version=2023-11-01"
        headers = {'Content-Type': 'application/json', 'api-key': self.search_key}
        
        payload = {
            "value": [
                {
                    "@odata.operation": "delete",
                    "id": document_id
                }
            ]
        }
        
        try:
            response = requests.post(url, headers=headers, json=payload)
            
            if response.status_code == 200:
                result = response.json()
                success_count = len([d for d in result.get('value', []) if d.get('status')])
                return success_count > 0
            else:
                print(f"âŒ Error deleting document {document_id}: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            print(f"âŒ Error deleting document {document_id}: {e}")
            return False
    
    def update_document_staffing(self, document_id, new_staffing_plan):
        """Update a document's staffing plan"""
        
        url = f"{self.search_endpoint}/indexes/{self.index_name}/docs/index?api-version=2023-11-01"
        headers = {'Content-Type': 'application/json', 'api-key': self.search_key}
        
        payload = {
            "value": [
                {
                    "@odata.operation": "merge",
                    "id": document_id,
                    "staffing_plan": new_staffing_plan
                }
            ]
        }
        
        try:
            response = requests.post(url, headers=headers, json=payload)
            
            if response.status_code == 200:
                result = response.json()
                success_count = len([d for d in result.get('value', []) if d.get('status')])
                return success_count > 0
            else:
                print(f"âŒ Error updating document {document_id}: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            print(f"âŒ Error updating document {document_id}: {e}")
            return False
    
    def fix_staffing_data(self):
        """Fix the staffing data by removing incorrect entries and updating existing ones"""
        
        print("ğŸ” Getting all documents from index...")
        documents = self.get_all_documents()
        
        if not documents:
            print("âŒ No documents found in index")
            return False
        
        print(f"ğŸ“„ Found {len(documents)} documents")
        
        # Identify documents to delete (those with null client_name and only staffing_plan)
        documents_to_delete = []
        documents_to_update = []
        
        for doc in documents:
            doc_id = doc.get('id', '')
            client_name = doc.get('client_name')
            project_title = doc.get('project_title')
            file_name = doc.get('file_name')
            staffing_plan = doc.get('staffing_plan', [])
            
            # Check if this is a staffing-only document (null client_name but has staffing data)
            if client_name is None and project_title is None and file_name is None and staffing_plan:
                documents_to_delete.append(doc_id)
                print(f"ğŸ—‘ï¸  Marked for deletion: {doc_id} (staffing-only document)")
            elif file_name:
                # This is a real SOW document - check if it needs staffing update
                documents_to_update.append(doc)
        
        # Delete the incorrect staffing-only documents
        deleted_count = 0
        if documents_to_delete:
            print(f"\nğŸ—‘ï¸  Deleting {len(documents_to_delete)} incorrect documents...")
            for doc_id in documents_to_delete:
                if self.delete_document(doc_id):
                    deleted_count += 1
                    print(f"   âœ… Deleted {doc_id}")
                else:
                    print(f"   âŒ Failed to delete {doc_id}")
        
        # Update existing SOW documents with detailed staffing data
        updated_count = 0
        print(f"\nğŸ”„ Updating existing SOW documents with detailed staffing data...")
        
        for doc in documents_to_update:
            file_name = doc.get('file_name', '')
            doc_id = doc.get('id', '')
            
            # Find matching detailed staffing data
            matching_key = None
            for key in self.detailed_staffing_data.keys():
                if key in file_name.lower().replace('.pdf', '').replace('.docx', '').replace('_', '_'):
                    matching_key = key
                    break
            
            if matching_key:
                new_staffing = self.detailed_staffing_data[matching_key]
                current_staffing = doc.get('staffing_plan', [])
                
                print(f"ğŸ“‹ Updating {file_name}")
                print(f"   Current staffing: {len(current_staffing)} entries")
                print(f"   New staffing: {len(new_staffing)} entries")
                
                if self.update_document_staffing(doc_id, new_staffing):
                    updated_count += 1
                    print(f"   âœ… Successfully updated")
                else:
                    print(f"   âŒ Failed to update")
            else:
                print(f"âš ï¸  No detailed staffing data found for {file_name}")
        
        print(f"\nğŸ“Š SUMMARY:")
        print(f"   Documents deleted: {deleted_count}")
        print(f"   Documents updated: {updated_count}")
        print(f"   Total SOW documents: {len(documents_to_update)}")
        
        return True
    
    def run(self):
        """Main execution method"""
        
        print("ğŸ”§ FIXING STAFFING DATA IN AZURE SEARCH INDEX")
        print("=" * 60)
        
        self.load_environment()
        success = self.fix_staffing_data()
        
        if success:
            print(f"\nâœ… Staffing data fix completed!")
            print(f"ğŸ¯ The index now has proper SOW documents with detailed staffing data")
        else:
            print(f"\nâŒ Staffing data fix failed")
        
        return success

if __name__ == "__main__":
    from pathlib import Path
    fixer = StaffingDataFixer()
    fixer.run()
