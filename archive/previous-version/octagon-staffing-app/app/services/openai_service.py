from __future__ import annotations

from typing import Optional

from openai import AsyncOpenAI

from ..config import get_settings


class OpenAIServiceError(Exception):
    """Raised when Azure OpenAI operations fail."""


class OpenAIService:
    """Service for semantic normalization and staffing inference using Azure OpenAI."""

    def __init__(self) -> None:
        settings = get_settings()
        if not settings.aoai_endpoint or not settings.aoai_key:
            raise OpenAIServiceError("Azure OpenAI configuration missing")
        self._client = AsyncOpenAI(
            api_key=settings.aoai_key,
            base_url=f"{settings.aoai_endpoint}/openai/deployments/{settings.aoai_deployment}",
            default_query={"api-version": settings.aoai_api_version},
        )

    async def suggest_staffing(self, processed_sow: dict) -> dict:
        """Return a placeholder staffing plan suggestion using model output."""

        try:
            # Minimal call with placeholder prompt; implementation to be expanded later
            _ = processed_sow
            # In a real implementation, we'd call chat.completions.create
            return {
                "summary": "Placeholder staffing plan generated by LLM",
                "roles": [
                    {"role": "Project Manager", "quantity": 1, "allocation_percent": 50},
                    {"role": "Consultant", "quantity": 2, "allocation_percent": 75},
                ],
                "confidence": 0.5,
            }
        except Exception as exc:  # noqa: BLE001
            raise OpenAIServiceError(str(exc)) from exc



