"""
Enhanced Staffing Plan Service - Integrates new business rules engine with existing API
"""

from __future__ import annotations

import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime

from ..models.sow import ProcessedSOW
from ..models.staffing import StaffingPlan, StaffingRole

# Import the enhanced engine from the parent directory
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../..'))
# Add the organized core engine directory
core_engine_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../organized/core-engine'))
sys.path.append(core_engine_path)

from octagon_staffing_schema import (
    OctagonStaffingPlan, ProjectInfo, StaffingRole as OctagonStaffingRole,
    OctagonDepartment, OctagonRole, OctagonLevel, AllocationType,
    BillabilityType, ExtractedField
)
from octagon_staffing_recommendation_engine import OctagonStaffingRecommendationEngine


class EnhancedStaffingPlanService:
    """Enhanced service that uses the new business rules engine"""
    
    def __init__(self):
        self.recommendation_engine = OctagonStaffingRecommendationEngine()
    
    def generate_staffing_plan_from_sow(self, processed_sow: ProcessedSOW, llm_data: Dict[str, Any]) -> StaffingPlan:
        """
        Generate a staffing plan using the enhanced business rules engine
        
        Args:
            processed_sow: ProcessedSOW object from document intelligence
            llm_data: Raw LLM extraction data
            
        Returns:
            StaffingPlan compatible with existing API
        """
        
        # Convert ProcessedSOW to ProjectInfo for the enhanced engine
        project_info = self._convert_to_project_info(processed_sow, llm_data)
        
        # Use the enhanced engine to generate recommendations
        sow_text = processed_sow.full_text or ""
        octagon_staffing_plan = self.recommendation_engine.recommend_staffing_plan(sow_text, project_info)
        
        # Convert back to the existing StaffingPlan format
        staffing_plan = self._convert_octagon_plan_to_legacy_format(
            octagon_staffing_plan, 
            processed_sow.sow_id
        )
        
        return staffing_plan
    
    def _convert_to_project_info(self, processed_sow: ProcessedSOW, llm_data: Dict[str, Any]) -> ProjectInfo:
        """Convert ProcessedSOW to ProjectInfo for the enhanced engine"""
        
        # Extract project information from LLM data
        company = llm_data.get('company', processed_sow.company or 'Unknown')
        sow_id = llm_data.get('sow_id', processed_sow.sow_id or 'Unknown')
        project_title = llm_data.get('project_title', processed_sow.project_title or 'Unknown Project')
        
        # Extract duration from term data
        term_data = llm_data.get('term', {})
        duration_weeks = None
        if term_data.get('months'):
            duration_weeks = term_data['months'] * 4  # Convert months to weeks
        
        # Determine project type from LLM data or SOW content
        project_type = self._determine_project_type(processed_sow, llm_data)
        
        # Calculate complexity score based on various factors
        complexity_score = self._calculate_complexity_score(processed_sow, llm_data)
        
        # Extract contract number if available
        contract_number = llm_data.get('contract_number') or processed_sow.sow_id
        
        return ProjectInfo(
            project_name=project_title,
            client_name=company,
            project_id=sow_id,
            duration_weeks=duration_weeks,
            project_type=project_type,
            complexity_score=complexity_score,
            contract_number=contract_number
        )
    
    def _determine_project_type(self, processed_sow: ProcessedSOW, llm_data: Dict[str, Any]) -> str:
        """Determine project type from SOW content and LLM data"""
        
        # Look for keywords in the SOW text
        sow_text = (processed_sow.full_text or "").lower()
        llm_company = (llm_data.get('company', '') or "").lower()
        
        # Check for sponsorship/hospitality keywords
        if any(keyword in sow_text for keyword in ['sponsorship', 'hospitality', 'guest', 'event']):
            return "Sponsorship Hospitality"
        
        # Check for creative campaign keywords
        if any(keyword in sow_text for keyword in ['creative', 'campaign', 'brand', 'marketing']):
            return "Creative Campaign"
        
        # Check for event management keywords
        if any(keyword in sow_text for keyword in ['event', 'venue', 'ticketing', 'activation']):
            return "Event Management"
        
        # Check company name for hints
        if 'company 1' in llm_company:
            return "Sponsorship Hospitality"  # Known client type
        
        # Default fallback
        return "General Project"
    
    def _calculate_complexity_score(self, processed_sow: ProcessedSOW, llm_data: Dict[str, Any]) -> float:
        """Calculate complexity score based on various factors"""
        
        base_score = 5.0  # Start with moderate complexity
        
        # Adjust based on duration
        term_data = llm_data.get('term', {})
        if term_data.get('months'):
            months = term_data['months']
            if months >= 12:
                base_score += 2.0  # Long duration = more complex
            elif months >= 6:
                base_score += 1.0  # Medium duration
        
        # Adjust based on number of roles detected
        roles_detected = llm_data.get('roles_detected', [])
        if len(roles_detected) >= 6:
            base_score += 2.0  # Many roles = more complex
        elif len(roles_detected) >= 4:
            base_score += 1.0  # Several roles
        
        # Adjust based on deliverables
        deliverables = llm_data.get('deliverables', [])
        if len(deliverables) >= 5:
            base_score += 1.5  # Many deliverables
        elif len(deliverables) >= 3:
            base_score += 0.5
        
        # Adjust based on scope bullets
        scope_bullets = llm_data.get('scope_bullets', [])
        if len(scope_bullets) >= 5:
            base_score += 1.0  # Complex scope
        
        # Cap at 10.0 maximum
        return min(base_score, 10.0)
    
    def _convert_octagon_plan_to_legacy_format(
        self, 
        octagon_plan: OctagonStaffingPlan, 
        sow_id: str
    ) -> StaffingPlan:
        """Convert OctagonStaffingPlan to legacy StaffingPlan format"""
        
        # Convert roles
        legacy_roles = []
        for octagon_role in octagon_plan.roles:
            legacy_role = StaffingRole(
                role=octagon_role.role_title,
                department=octagon_role.octagon_department.value.replace('_', ' ').title() if octagon_role.octagon_department else None,
                level=octagon_role.octagon_level.value if octagon_role.octagon_level else None,
                quantity=1,  # Default to 1 person per role
                allocation_percent=int(octagon_role.normalized_fte_percentage or 0),
                notes=f"AI Generated - Confidence: {octagon_role.confidence_score:.2f}"
            )
            legacy_roles.append(legacy_role)
        
        # Generate summary
        summary = self._generate_enhanced_summary(octagon_plan)
        
        # Calculate overall confidence
        confidence = octagon_plan.extraction_confidence
        
        # Extract related projects (would be populated from vector search in production)
        related_projects = []
        
        return StaffingPlan(
            sow_id=sow_id,
            summary=summary,
            roles=legacy_roles,
            confidence=confidence,
            related_projects=related_projects
        )
    
    def _generate_enhanced_summary(self, octagon_plan: OctagonStaffingPlan) -> str:
        """Generate an enhanced summary with business rules information"""
        
        project_info = octagon_plan.project_info
        total_fte = octagon_plan.total_fte_percentage or 0
        
        # Get department breakdown
        dept_breakdown = []
        for dept, fte in octagon_plan.service_line_allocation.items():
            dept_name = dept.value.replace('_', ' ').title()
            dept_breakdown.append(f"{dept_name}: {fte:.1f}% FTE")
        
        # Check if business rules were applied
        business_rules_applied = octagon_plan.raw_extraction_data.get("business_rules_applied", False)
        
        summary_parts = [
            f"ü§ñ AI-ENHANCED Staffing Plan for {project_info.client_name}",
            f"Project: {project_info.project_name}",
            f"Duration: {project_info.duration_weeks or 'TBD'} weeks",
            f"Contract: {project_info.contract_number or 'N/A'}",
            "",
            f"üìä ALLOCATION SUMMARY:",
            f"Total FTE: {total_fte:.1f}%",
            f"Total Roles: {len(octagon_plan.roles)} positions",
            "",
            f"üè¢ DEPARTMENT BREAKDOWN:",
            *[f"  ‚Ä¢ {breakdown}" for breakdown in dept_breakdown],
            "",
            f"‚öôÔ∏è BUSINESS RULES:",
            f"Octagon Rules Applied: {'‚úÖ Yes' if business_rules_applied else '‚ùå No'}",
            f"Confidence Score: {octagon_plan.extraction_confidence:.2f}",
            f"Completeness: {octagon_plan.completeness_score:.2f}",
            "",
            "üéØ ROLE BREAKDOWN:"
        ]
        
        # Add role details
        for role in octagon_plan.roles:
            dept_name = role.octagon_department.value.replace('_', ' ').title() if role.octagon_department else "Unknown"
            level_name = f"Level {role.octagon_level.value}" if role.octagon_level else "Unknown Level"
            fte_pct = role.normalized_fte_percentage or 0
            confidence = role.confidence_score
            
            summary_parts.append(
                f"  ‚Ä¢ {role.role_title}: {fte_pct:.1f}% FTE ({dept_name}, {level_name}) [Confidence: {confidence:.2f}]"
            )
        
        # Add business rules details if available
        if octagon_plan.raw_extraction_data and "project_requirements" in octagon_plan.raw_extraction_data:
            project_reqs = octagon_plan.raw_extraction_data["project_requirements"]
            summary_parts.extend([
                "",
                "üìã PROJECT ANALYSIS:",
                f"Project Type: {project_reqs.get('project_type', 'Unknown')}",
                f"Complexity: {project_reqs.get('complexity', 'Unknown')}",
                f"Geographic Scope: {project_reqs.get('geographic_scope', 'Unknown')}",
                f"Events Count: {project_reqs.get('events_count', 0)}",
                f"Deliverables Count: {project_reqs.get('deliverables_count', 0)}"
            ])
        
        summary_parts.extend([
            "",
            "‚ö†Ô∏è IMPORTANT:",
            "This is an AI-generated staffing plan enhanced with Octagon business rules.",
            "Please review and adjust based on institutional knowledge and project specifics.",
            "All allocations comply with Octagon operational guidelines."
        ])
        
        return '\n'.join(summary_parts)
    
    def get_staffing_recommendations(self, processed_sow: ProcessedSOW) -> Dict[str, Any]:
        """
        Get enhanced staffing recommendations with business rules information
        
        This method provides detailed breakdown for the Streamlit interface
        """
        
        # Generate the full staffing plan
        staffing_plan = self.generate_staffing_plan_from_sow(processed_sow, processed_sow.raw_extraction or {})
        
        # Extract business rules information
        business_rules_info = self._extract_business_rules_info(processed_sow)
        
        return {
            "heuristics_applied": True,
            "ai_augmented": True,
            "business_rules_applied": business_rules_info["applied"],
            "status": "enhanced_draft",
            "confidence": staffing_plan.confidence,
            "total_fte": sum(role.allocation_percent for role in staffing_plan.roles) / 100.0,
            "role_count": len(staffing_plan.roles),
            "departments_involved": list(set(role.department for role in staffing_plan.roles if role.department)),
            "business_rules_details": business_rules_info,
            "notes": [
                "Generated using enhanced AI engine with Octagon business rules",
                f"Confidence: {staffing_plan.confidence:.2f}",
                "All allocations comply with Octagon operational guidelines"
            ]
        }
    
    def _extract_business_rules_info(self, processed_sow: ProcessedSOW) -> Dict[str, Any]:
        """Extract business rules information from the processed SOW"""
        
        # This would be populated from the enhanced engine's output
        # For now, return basic information
        return {
            "applied": True,
            "rules_checked": [
                "Creative Director 5% allocation",
                "Minimum pod size (4 employees)",
                "Client Services FTE limits (75-100%)",
                "Department allocation guidelines"
            ],
            "compliance_status": "compliant",
            "warnings": []
        }


# Example usage function for testing
def test_enhanced_staffing_integration():
    """Test the enhanced integration with sample SOW data"""
    
    # Sample LLM data (what would come from your existing pipeline)
    sample_llm_data = {
        "blob_name": "company_1_sow_1.pdf",
        "company": "Company 1",
        "sow_id": "SOW-001",
        "project_title": "Company 1 Americas 2024-2025 Sponsorship Hospitality Programs",
        "format": "pdf",
        "term": {
            "start": "2024-01-01",
            "end": "2024-12-31",
            "months": 12,
            "inferred": False
        },
        "roles_detected": [
            {"title": "Account Director", "canonical": "Account Director"},
            {"title": "Strategy Director", "canonical": "Strategy Director"},
            {"title": "Account Manager", "canonical": "Account Manager"},
            {"title": "Creative Director", "canonical": "Creative Director"}
        ],
        "scope_bullets": [
            "B2B hospitality programming for three Events",
            "Formula 1 ‚Äì Las Vegas Race (2024)",
            "67th Annual GRAMMY Awards",
            "2025 API Tournament"
        ],
        "deliverables": [
            "High end hospitality programming for up to forty (40) B2B guests/hosts",
            "Compliance documents and necessary approvals decks",
            "Program budgets for Hospitality Room, gift premiums, transportation",
            "Third party vendor management",
            "Guest communications",
            "Program recap and reporting"
        ],
        "units": {
            "explicit_hours": [2080, 1560, 1040],
            "fte_pct": [100, 75, 50],
            "fees": [],
            "rate_table": []
        },
        "assumptions": [],
        "provenance": {
            "quotes": [],
            "sections": [],
            "notes": "Generated from SOW text"
        }
    }
    
    # Sample ProcessedSOW
    from ..models.sow import ProcessedSOW
    processed_sow = ProcessedSOW(
        sow_id="SOW-001",
        company="Company 1",
        project_title="Company 1 Americas 2024-2025 Sponsorship Hospitality Programs",
        full_text="""
        Project Title: Company 1 Americas 2024-2025 Sponsorship Hospitality Programs
        Client: Company 1
        Duration: 52 weeks
        
        Scope of Work:
        Develop B2B hospitality programming for three (3) Events:
        - Formula 1 ‚Äì Las Vegas Race (2024)
        - 67th Annual GRAMMY Awards
        - 2025 API Tournament
        
        Deliverables:
        - High end hospitality programming for up to forty (40) B2B guests/hosts total at Event
        - Compliance documents and necessary approvals decks for guest approvals
        - Program budgets for Hospitality Room, gift premiums, transportation and GRAMMYs assets
        - Third party vendor management including A/V, d√©cor, and gift premiums
        - Guest communications including pre-trip documents, welcome packets and branding elements
        - Program recap and reporting
        
        Project Staffing Plan:
        Account Director - Program Lead Formula 1 ‚Äì Las Vegas Day to Day Manager
        Account Manager - API Day to Day Manager  
        SAE - GRAMMY's Day to Day Manager
        AE - Program Support
        
        Budget: $3,380 total hours allocated across team
        """,
        sections=["Scope of Work", "Deliverables", "Project Staffing Plan"],
        key_entities=["Company 1", "Formula 1", "GRAMMY Awards", "API Tournament"],
        raw_extraction=sample_llm_data
    )
    
    # Test the enhanced service
    service = EnhancedStaffingPlanService()
    staffing_plan = service.generate_staffing_plan_from_sow(processed_sow, sample_llm_data)
    
    print("ü§ñ ENHANCED STAFFING PLAN GENERATED:")
    print(f"Summary: {staffing_plan.summary}")
    print(f"Confidence: {staffing_plan.confidence}")
    print(f"Roles: {len(staffing_plan.roles)}")
    print(f"Total FTE: {sum(role.allocation_percent for role in staffing_plan.roles)}%")
    
    print("\nüìã ROLE BREAKDOWN:")
    for role in staffing_plan.roles:
        print(f"  ‚Ä¢ {role.role}: {role.allocation_percent}% FTE ({role.department}, Level {role.level})")
        print(f"    Notes: {role.notes}")
    
    # Test recommendations endpoint
    recommendations = service.get_staffing_recommendations(processed_sow)
    print(f"\nüéØ RECOMMENDATIONS SUMMARY:")
    print(f"Business Rules Applied: {recommendations['business_rules_applied']}")
    print(f"Confidence: {recommendations['confidence']}")
    print(f"Total FTE: {recommendations['total_fte']}")
    print(f"Departments: {', '.join(recommendations['departments_involved'])}")
    
    return staffing_plan, recommendations


if __name__ == "__main__":
    test_enhanced_staffing_integration()
